{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import  nn\n",
    "import os\n",
    "\n",
    "# added\n",
    "import datetime\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import scipy.ndimage as nd\n",
    "import scipy.io as io\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "\n",
    "import skimage.measure as sk\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.gridspec as gridspec\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import pickle\n",
    "\n",
    "from collections import OrderedDict\n",
    "import binvox_rw as binvox\n",
    "\n",
    "\n",
    "from model import net_G, net_D\n",
    "# from utils import *\n",
    "import params\n",
    "import argparse\n",
    "\n",
    "# if params.device.type != 'cpu':\n",
    "#     matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\lamga\\\\OneDrive - Harvard University\\\\Gabe and Jan\\\\2021_Machine and Intuition\\\\updated_GAN\\\\simple-pytorch-3dgan-master'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "params.py\n",
    "\n",
    "Managers of all hyper-parameters\n",
    "\n",
    "'''\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 64\n",
    "soft_label = False\n",
    "adv_weight = 0\n",
    "d_thresh = 0.9\n",
    "z_dim = 256\n",
    "z_dis = \"norm\"\n",
    "model_save_step = 5\n",
    "g_lr = 0.00025\n",
    "d_lr = 0.00001\n",
    "beta = (0.5, 0.999)\n",
    "cube_len = 32\n",
    "leak_value = 0.2\n",
    "bias = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_dir = './volumetric_data/'\n",
    "model_dir = 'chair/'    # change it to train on other data models\n",
    "output_dir = './outputs'\n",
    "images_dir = './images'\n",
    "array_dir = './array/'\n",
    "\n",
    "def print_params():\n",
    "    l = 16\n",
    "    print (l*'*' + 'hyper-parameters' + l*'*')\n",
    "\n",
    "    print ('epochs =', epochs)\n",
    "    print ('batch_size =', batch_size)\n",
    "    print ('soft_labels =', soft_label)\n",
    "    print ('adv_weight =', adv_weight)\n",
    "    print ('d_thresh =', d_thresh)\n",
    "    print ('z_dim =', z_dim)\n",
    "    print ('z_dis =', z_dis)\n",
    "    print ('model_images_save_step =', model_save_step)\n",
    "    print ('data =', model_dir)\n",
    "    print ('device =', device)\n",
    "    print ('g_lr =', g_lr)\n",
    "    print ('d_lr =', d_lr)\n",
    "    print ('cube_len =', cube_len)\n",
    "    print ('leak_value =', leak_value)\n",
    "    print ('bias =', bias)\n",
    "\n",
    "    print (l*'*' + 'hyper-parameters' + l*'*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "utils.py\n",
    "\n",
    "Some utility functions\n",
    "\n",
    "'''\n",
    "\n",
    "def getVoxelFromMat(filename, cube_len=32):\n",
    "    if cube_len == 32:\n",
    "        with open(filename, 'rb') as f:\n",
    "            model = binvox.read_as_3d_array(f)\n",
    "            voxels = model.data.astype(np.float32)\n",
    "#     return voxels[:,:,:,0]\n",
    "    return voxels\n",
    "\n",
    "\n",
    "def getVFByMarchingCubes(voxels, threshold=0.5):\n",
    "    v, f = sk.marching_cubes_classic(voxels, level=threshold)\n",
    "    return v, f\n",
    "\n",
    "\n",
    "def plotVoxelVisdom(voxels, visdom, title):\n",
    "    v, f = getVFByMarchingCubes(voxels)\n",
    "    visdom.mesh(X=v, Y=f, opts=dict(opacity=0.5, title=title))\n",
    "\n",
    "\n",
    "def SavePloat_Voxels(voxels, path, iteration):\n",
    "    voxels = voxels[:8].__ge__(0.5)\n",
    "    fig = plt.figure(figsize=(32, 16))\n",
    "    gs = gridspec.GridSpec(2, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(voxels):\n",
    "        x, y, z = sample.nonzero()\n",
    "        ax = plt.subplot(gs[i], projection='3d')\n",
    "        ax.scatter(z, x, y, zdir='z', c='red')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('auto')\n",
    "    # print (path + '/{}.png'.format(str(iteration).zfill(3)))\n",
    "    plt.savefig(path + '/{}.png'.format(str(iteration).zfill(3)), bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "def Save_Array(voxels, path, iteration):\n",
    "    voxels = voxels[:8].__ge__(0.5)\n",
    "    array_list = []\n",
    "    for i, sample in enumerate(voxels):\n",
    "        x, y, z = sample.nonzero()\n",
    "        array_list.append(np.asarray((x,y,z)))\n",
    "    # print (path + '/{}.png'.format(str(iteration).zfill(3)))\n",
    "    np.savetxt(array_dir + str(iteration) + \".csv\", array_list[-1], delimiter=\",\")\n",
    "\n",
    "\n",
    "\n",
    "class ShapeNetDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, root, args, train_or_val=\"train\"):\n",
    "        \n",
    "        \n",
    "        self.root = root\n",
    "        self.listdir = os.listdir(self.root)\n",
    "        # print (self.listdir)  \n",
    "        # print (len(self.listdir)) # 10668\n",
    "\n",
    "        data_size = len(self.listdir)\n",
    "#        self.listdir = self.listdir[0:int(data_size*0.7)]\n",
    "        self.listdir = self.listdir[0:int(data_size)]\n",
    "        \n",
    "        print ('data_size =', len(self.listdir)) # train: 10668-1000=9668\n",
    "        self.args = args\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         with open(self.root + self.listdir[index], \"rb\") as f:\n",
    "#             print(self.root + self.listdir[index])\n",
    "#             volume = np.asarray(getVoxelFromMat(f, params.cube_len), dtype=np.float32)\n",
    "        volume = getVoxelFromMat(self.root + self.listdir[index], params.cube_len)\n",
    "            # print (volume.shape)\n",
    "        return torch.FloatTensor(volume)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.listdir)\n",
    "\n",
    "\n",
    "def generateZ(args, batch):\n",
    "\n",
    "    if params.z_dis == \"norm\":\n",
    "        Z = torch.Tensor(batch, params.z_dim).normal_(0, 0.33).to(params.device)\n",
    "    elif params.z_dis == \"uni\":\n",
    "        Z = torch.randn(batch, params.z_dim).to(params.device).to(params.device)\n",
    "    else:\n",
    "        print(\"z_dist is not normal or uniform\")\n",
    "\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import params\n",
    "\n",
    "'''\n",
    "\n",
    "model.py\n",
    "\n",
    "Define our GAN model\n",
    "\n",
    "The cube_len is 32x32x32, and the maximum number of feature map is 256, \n",
    "so the results may be inconsistent with the paper\n",
    "\n",
    "'''\n",
    "\n",
    "class net_G(torch.nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(net_G, self).__init__()\n",
    "        self.args = args\n",
    "        self.cube_len = params.cube_len\n",
    "        self.bias = params.bias\n",
    "        self.z_dim = params.z_dim\n",
    "        self.f_dim = 32\n",
    "\n",
    "        padd = (0, 0, 0)\n",
    "        if self.cube_len == 32:\n",
    "            padd = (1,1,1)\n",
    "\n",
    "        self.layer1 = self.conv_layer(self.z_dim, self.f_dim*8, kernel_size=4, stride=2, padding=padd, bias=self.bias)\n",
    "        self.layer2 = self.conv_layer(self.f_dim*8, self.f_dim*4, kernel_size=4, stride=2, padding=(1, 1, 1), bias=self.bias)\n",
    "        self.layer3 = self.conv_layer(self.f_dim*4, self.f_dim*2, kernel_size=4, stride=2, padding=(1, 1, 1), bias=self.bias)\n",
    "        self.layer4 = self.conv_layer(self.f_dim*2, self.f_dim, kernel_size=4, stride=2, padding=(1, 1, 1), bias=self.bias)\n",
    "        \n",
    "        self.layer5 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose3d(self.f_dim, 1, kernel_size=4, stride=2, bias=self.bias, padding=(1, 1, 1)),\n",
    "            torch.nn.Sigmoid()\n",
    "            # torch.nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def conv_layer(self, input_dim, output_dim, kernel_size=4, stride=2, padding=(1,1,1), bias=False):\n",
    "        layer = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose3d(input_dim, output_dim, kernel_size=kernel_size, stride=stride, bias=bias, padding=padding),\n",
    "            torch.nn.BatchNorm3d(output_dim),\n",
    "            torch.nn.ReLU(True)\n",
    "            # torch.nn.LeakyReLU(self.leak_value, True)\n",
    "        )\n",
    "        return layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x.view(-1, self.z_dim, 1, 1, 1)\n",
    "        # print(out.size())  # torch.Size([32, 200, 1, 1, 1])\n",
    "        out = self.layer1(out)\n",
    "        # print(out.size())  # torch.Size([32, 256, 2, 2, 2])\n",
    "        out = self.layer2(out)\n",
    "        # print(out.size())  # torch.Size([32, 128, 4, 4, 4])\n",
    "        out = self.layer3(out)\n",
    "        # print(out.size())  # torch.Size([32, 64, 8, 8, 8])\n",
    "        out = self.layer4(out)\n",
    "        # print(out.size())  # torch.Size([32, 32, 16, 16, 16])\n",
    "        out = self.layer5(out)\n",
    "        # print(out.size())  # torch.Size([32, 1, 32, 32, 32])\n",
    "        out = torch.squeeze(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class net_D(torch.nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(net_D, self).__init__()\n",
    "        self.args = args\n",
    "        self.cube_len = params.cube_len\n",
    "        self.leak_value = params.leak_value\n",
    "        self.bias = params.bias\n",
    "\n",
    "        padd = (0,0,0)\n",
    "        if self.cube_len == 32:\n",
    "            padd = (1,1,1)\n",
    "\n",
    "        self.f_dim = 32\n",
    "\n",
    "        self.layer1 = self.conv_layer(1, self.f_dim, kernel_size=4, stride=2, padding=(1,1,1), bias=self.bias)\n",
    "        self.layer2 = self.conv_layer(self.f_dim, self.f_dim*2, kernel_size=4, stride=2, padding=(1,1,1), bias=self.bias)\n",
    "        self.layer3 = self.conv_layer(self.f_dim*2, self.f_dim*4, kernel_size=4, stride=2, padding=(1,1,1), bias=self.bias)\n",
    "        self.layer4 = self.conv_layer(self.f_dim*4, self.f_dim*8, kernel_size=4, stride=2, padding=(1,1,1), bias=self.bias)\n",
    "\n",
    "        self.layer5 = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(self.f_dim*8, 1, kernel_size=4, stride=2, bias=self.bias, padding=padd),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # self.layer5 = torch.nn.Sequential(\n",
    "        #     torch.nn.Linear(256*2*2*2, 1),\n",
    "        #     torch.nn.Sigmoid()\n",
    "        # )\n",
    "\n",
    "    def conv_layer(self, input_dim, output_dim, kernel_size=4, stride=2, padding=(1,1,1), bias=False):\n",
    "        layer = torch.nn.Sequential(\n",
    "        torch.nn.Conv3d(input_dim, output_dim, kernel_size=kernel_size, stride=stride, bias=bias, padding=padding),\n",
    "        torch.nn.BatchNorm3d(output_dim),\n",
    "        torch.nn.LeakyReLU(self.leak_value, inplace=True)\n",
    "        )\n",
    "        return layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # out = torch.unsqueeze(x, dim=1)\n",
    "        out = x.view(-1, 1, self.cube_len, self.cube_len, self.cube_len)\n",
    "        # print(out.size()) # torch.Size([32, 1, 32, 32, 32])\n",
    "        out = self.layer1(out)\n",
    "        # print(out.size())  # torch.Size([32, 32, 16, 16, 16])\n",
    "        out = self.layer2(out)\n",
    "        # print(out.size())  # torch.Size([32, 64, 8, 8, 8])\n",
    "        out = self.layer3(out)\n",
    "        # print(out.size())  # torch.Size([32, 128, 4, 4, 4])\n",
    "        out = self.layer4(out)\n",
    "        # print(out.size())  # torch.Size([32, 256, 2, 2, 2])\n",
    "        # out = out.view(-1, 256*2*2*2)\n",
    "        # print (out.size())\n",
    "        out = self.layer5(out)\n",
    "        # print(out.size())  # torch.Size([32, 1, 1, 1, 1])\n",
    "        out = torch.squeeze(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "trainer.py\n",
    "\n",
    "Train 3dgan models\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def save_train_log(writer, loss_D, loss_G, itr):\n",
    "    scalar_info = {}\n",
    "    for key, value in loss_G.items():\n",
    "        scalar_info['train_loss_G/' + key] = value\n",
    "        \n",
    "    for key, value in loss_D.items():\n",
    "        scalar_info['train_loss_D/' + key] = value\n",
    "\n",
    "    for tag, value in scalar_info.items():\n",
    "        writer.add_scalar(tag, value, itr)\n",
    "\n",
    "def save_val_log(writer, loss_D, loss_G, itr):\n",
    "    scalar_info = {}\n",
    "    for key, value in loss_G.items():\n",
    "        scalar_info['val_loss_G/' + key] = value\n",
    "        \n",
    "    for key, value in loss_D.items():\n",
    "        scalar_info['val_loss_D/' + key] = value\n",
    "\n",
    "    for tag, value in scalar_info.items():\n",
    "        writer.add_scalar(tag, value, itr)\n",
    "\n",
    "\n",
    "def trainer(args):\n",
    "\n",
    "    # added for output dir\n",
    "    save_file_path = params.output_dir + '/' + args.model_name\n",
    "    print (save_file_path)  # ../outputs/dcgan\n",
    "    if not os.path.exists(save_file_path):\n",
    "        os.makedirs(save_file_path)\n",
    "\n",
    "    # for using tensorboard\n",
    "    if args.logs:\n",
    "        model_uid = datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "        writer = SummaryWriter(params.output_dir+'/'+args.model_name+'/logs_'+model_uid+'_'+args.logs+'/')\n",
    "\n",
    "    # datset define\n",
    "#     dsets_path = params.data_dir + params.model_dir + \"30/train/\"\n",
    "    dsets_path = 'C:/Users/lamga/OneDrive - Harvard University/Thesis/GAN/simple-pytorch-3dgan-master/volumetric_data/chair/30/train/'\n",
    "    # if params.cube_len == 64:\n",
    "    #     dsets_path = params.data_dir + params.model_dir + \"30/train64/\"\n",
    "\n",
    "    print (dsets_path)   # ../volumetric_data/chair/30/train/\n",
    "\n",
    "    train_dsets = ShapeNetDataset(dsets_path, args, \"train\")\n",
    "    # val_dsets = ShapeNetDataset(dsets_path, args, \"val\")\n",
    "    \n",
    "    train_dset_loaders = torch.utils.data.DataLoader(train_dsets, batch_size=params.batch_size, shuffle=True, num_workers=0)\n",
    "    # val_dset_loaders = torch.utils.data.DataLoader(val_dsets, batch_size=args.batch_size, shuffle=True, num_workers=1)\n",
    "    \n",
    "    dset_len = {\"train\": len(train_dsets)}\n",
    "    dset_loaders = {\"train\": train_dset_loaders}\n",
    "    # print (dset_len[\"train\"])\n",
    "\n",
    "    # model define\n",
    "    D = net_D(args)\n",
    "    G = net_G(args)\n",
    "\n",
    "    # print total number of parameters in a model\n",
    "    # x = sum(p.numel() for p in G.parameters() if p.requires_grad)\n",
    "    # print (x)\n",
    "    # x = sum(p.numel() for p in D.parameters() if p.requires_grad)\n",
    "    # print (x)\n",
    "\n",
    "    D_solver = optim.Adam(D.parameters(), lr=params.d_lr, betas=params.beta)\n",
    "    # D_solver = optim.SGD(D.parameters(), lr=args.d_lr, momentum=0.9)\n",
    "    G_solver = optim.Adam(G.parameters(), lr=params.g_lr, betas=params.beta)\n",
    "\n",
    "    D.to(params.device)\n",
    "    G.to(params.device)\n",
    "    \n",
    "\n",
    "    # criterion_D = nn.BCELoss()\n",
    "    criterion_D = nn.MSELoss()\n",
    "    criterion_G = nn.L1Loss()\n",
    "\n",
    "    itr_val = -1\n",
    "    itr_train = -1\n",
    "\n",
    "    for epoch in range(params.epochs):\n",
    "\n",
    "        start = time.time()\n",
    "        \n",
    "        for phase in ['train']:\n",
    "            if phase == 'train':\n",
    "                # if args.lrsh:\n",
    "                #     D_scheduler.step()\n",
    "                D.train()\n",
    "                G.train()\n",
    "            else:\n",
    "                D.eval()\n",
    "                G.eval()\n",
    "\n",
    "            running_loss_G = 0.0\n",
    "            running_loss_D = 0.0\n",
    "            running_loss_adv_G = 0.0\n",
    "\n",
    "            for i, X in enumerate(tqdm(dset_loaders[phase])):\n",
    "\n",
    "                # if phase == 'val':\n",
    "                #     itr_val += 1\n",
    "\n",
    "                if phase == 'train':\n",
    "                    itr_train += 1\n",
    "\n",
    "                X = X.to(params.device)\n",
    "                # print (X)\n",
    "                # print (X.size())\n",
    "                \n",
    "                batch = X.size()[0]\n",
    "                # print (batch)\n",
    "\n",
    "                Z = generateZ(args, batch)\n",
    "#                 print (Z.size())\n",
    "\n",
    "                # ============= Train the discriminator =============#\n",
    "                d_real = D(X)\n",
    "\n",
    "                \n",
    "\n",
    "                fake = G(Z)\n",
    "                d_fake = D(fake)\n",
    "\n",
    "                real_labels = torch.ones_like(d_real).to(params.device)\n",
    "                fake_labels = torch.zeros_like(d_fake).to(params.device)\n",
    "                # print (d_fake.size(), fake_labels.size())\n",
    "\n",
    "                if params.soft_label:\n",
    "                    real_labels = torch.Tensor(batch).uniform_(0.7, 1.2).to(params.device)\n",
    "                    fake_labels = torch.Tensor(batch).uniform_(0, 0.3).to(params.device)\n",
    "\n",
    "                # print (d_real.size(), real_labels.size())\n",
    "                d_real_loss = criterion_D(d_real, real_labels)\n",
    "                \n",
    "\n",
    "                d_fake_loss = criterion_D(d_fake, fake_labels)\n",
    "\n",
    "                d_loss = d_real_loss + d_fake_loss\n",
    "\n",
    "                # no deleted\n",
    "                d_real_acu = torch.ge(d_real.squeeze(), 0.5).float()\n",
    "                d_fake_acu = torch.le(d_fake.squeeze(), 0.5).float()\n",
    "                d_total_acu = torch.mean(torch.cat((d_real_acu, d_fake_acu),0))\n",
    "\n",
    "\n",
    "                if d_total_acu < params.d_thresh:\n",
    "                    D.zero_grad()\n",
    "                    d_loss.backward()\n",
    "                    D_solver.step()\n",
    "\n",
    "                # =============== Train the generator ===============#\n",
    "                \n",
    "                Z = generateZ(args, batch)\n",
    "\n",
    "                # print (X)\n",
    "                fake = G(Z) # generated fake: 0-1, X: 0/1\n",
    "                d_fake = D(fake)\n",
    "\n",
    "                adv_g_loss = criterion_D(d_fake, real_labels)\n",
    "                # print (fake.size(), X.size())\n",
    "\n",
    "                # recon_g_loss = criterion_D(fake, X)\n",
    "                recon_g_loss = criterion_G(fake, X)\n",
    "                # g_loss = recon_g_loss + params.adv_weight * adv_g_loss\n",
    "                g_loss = adv_g_loss\n",
    "\n",
    "                if args.local_test:\n",
    "                    # print('Iteration-{} , D(x) : {:.4} , G(x) : {:.4} , D(G(x)) : {:.4}'.format(itr_train, d_loss.item(), recon_g_loss.item(), adv_g_loss.item()))\n",
    "                    print('Iteration-{} , D(x) : {:.4}, D(G(x)) : {:.4}'.format(itr_train, d_loss.item(), adv_g_loss.item()))\n",
    "\n",
    "                D.zero_grad()\n",
    "                G.zero_grad()\n",
    "                g_loss.backward()\n",
    "                G_solver.step()\n",
    "\n",
    "                # =============== logging each 10 iterations ===============#\n",
    "\n",
    "                running_loss_G += recon_g_loss.item() * X.size(0)\n",
    "                running_loss_D += d_loss.item() * X.size(0)\n",
    "                running_loss_adv_G += adv_g_loss.item() * X.size(0)\n",
    "\n",
    "                if args.logs:\n",
    "                    loss_G = {\n",
    "                        'adv_loss_G': adv_g_loss,\n",
    "                        'recon_loss_G': recon_g_loss,   \n",
    "                    }\n",
    "\n",
    "                    loss_D = {\n",
    "                        'adv_real_loss_D': d_real_loss,\n",
    "                        'adv_fake_loss_D': d_fake_loss,\n",
    "                    }\n",
    "\n",
    "                    # if itr_val % 10 == 0 and phase == 'val':\n",
    "                    #     save_val_log(writer, loss_D, loss_G, itr_val)\n",
    "\n",
    "                    if itr_train % 10 == 0 and phase == 'train':\n",
    "                        save_train_log(writer, loss_D, loss_G, itr_train)\n",
    "\n",
    "           \n",
    "            # =============== each epoch save model or save image ===============#\n",
    "            epoch_loss_G = running_loss_G / dset_len[phase]\n",
    "            epoch_loss_D = running_loss_D / dset_len[phase]\n",
    "            epoch_loss_adv_G = running_loss_adv_G / dset_len[phase]\n",
    "\n",
    "\n",
    "            end = time.time()\n",
    "            epoch_time = end - start\n",
    "\n",
    "\n",
    "            print('Epochs-{} ({}) , D(x) : {:.4}, D(G(x)) : {:.4}'.format(epoch, phase, epoch_loss_D, epoch_loss_adv_G))\n",
    "            print ('Elapsed Time: {:.4} min'.format(epoch_time/60.0))\n",
    "\n",
    "            if (epoch + 1) % params.model_save_step == 0:\n",
    "\n",
    "                print ('model_saved, images_saved...')\n",
    "#                 torch.save(G.state_dict(), params.output_dir + '/' + args.model_name + '/' + 'G' + '.pth')\n",
    "#                 torch.save(D.state_dict(), params.output_dir + '/' + args.model_name + '/' + 'D' + '.pth')\n",
    "                torch.save(G.state_dict(), 'C:/Users/lamga/Documents/dcgan_output_test' + '/' + 'G' + '.pth')\n",
    "                torch.save(D.state_dict(), 'C:/Users/lamga/Documents/dcgan_output_test' + '/' + 'D' + '.pth')\n",
    "\n",
    "                \n",
    "                \n",
    "                samples = fake.cpu().data[:8].squeeze().numpy()\n",
    "                # print (samples.shape)\n",
    "                # image_saved_path = '../images'\n",
    "                image_saved_path = params.images_dir\n",
    "                if not os.path.exists(image_saved_path):\n",
    "                    os.makedirs(image_saved_path)\n",
    "\n",
    "                SavePloat_Voxels(samples, image_saved_path, epoch)\n",
    "                Save_Array(samples, array_dir, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "tester.py\n",
    "\n",
    "Test the trained 3dgan models\n",
    "'''\n",
    "# def test_gen(args):\n",
    "#     test_z = []\n",
    "#     test_num = 1000\n",
    "#     for i in range(test_num):\n",
    "#         z = generateZ(args, 1)\n",
    "#         z = z.numpy()\n",
    "#         test_z.append(z)\n",
    "    \n",
    "#     test_z = np.array(test_z)\n",
    "#     print (test_z.shape)\n",
    "    # np.save(\"test_z\", test_z)\n",
    "\n",
    "def tester(args):\n",
    "    print ('Evaluation Mode...')\n",
    "\n",
    "    # image_saved_path = '../images'\n",
    "    image_saved_path = params.images_dir\n",
    "    if not os.path.exists(image_saved_path):\n",
    "        os.makedirs(image_saved_path)\n",
    "\n",
    "    if args.use_visdom == True:\n",
    "        vis = visdom.Visdom()\n",
    "\n",
    "    save_file_path = params.output_dir + '/' + args.model_name\n",
    "    pretrained_file_path_G = save_file_path+'/'+'G.pth'\n",
    "    pretrained_file_path_D = save_file_path+'/'+'D.pth'\n",
    "    \n",
    "    print (pretrained_file_path_G)\n",
    "\n",
    "    D = net_D(args)\n",
    "    G = net_G(args)\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "        G.load_state_dict(torch.load(pretrained_file_path_G, map_location={'cuda:0': 'cpu'}))\n",
    "        D.load_state_dict(torch.load(pretrained_file_path_D, map_location={'cuda:0': 'cpu'}))\n",
    "    else:\n",
    "        G.load_state_dict(torch.load(pretrained_file_path_G))\n",
    "        D.load_state_dict(torch.load(pretrained_file_path_D, map_location={'cuda:0': 'cpu'}))\n",
    "    \n",
    "    print ('visualizing model')\n",
    "    \n",
    "    # test generator\n",
    "    # test_gen(args)\n",
    "    G.to(params.device)\n",
    "    D.to(params.device)\n",
    "    G.eval()\n",
    "    D.eval()\n",
    "\n",
    "    # test_z = np.load(\"test_z.npy\")\n",
    "    # print (test_z.shape)\n",
    "    # N = test_z.shape[0]\n",
    "\n",
    "    N = 8\n",
    "\n",
    "    for i in range(N):\n",
    "        # z = test_z[i,:]\n",
    "        # z = torch.FloatTensor(z)\n",
    "        \n",
    "        z = generateZ(args, 1)\n",
    "        \n",
    "        # print (z.size())\n",
    "        fake = G(z)\n",
    "        samples = fake.unsqueeze(dim=0).cpu().detach().numpy()\n",
    "        # print (samples.shape)\n",
    "        # print (fake)\n",
    "        y_prob = D(fake)\n",
    "        y_real = torch.ones_like(y_prob)\n",
    "        # criterion = nn.BCELoss()\n",
    "        # print (y_prob.item(), criterion(y_prob, y_real).item())\n",
    "\n",
    "        ### visualization\n",
    "        if args.use_visdom == False:\n",
    "            SavePloat_Voxels(samples, image_saved_path, 'tester_norm_'+str(i))\n",
    "        else:\n",
    "            plotVoxelVisdom(samples[0,:], vis, \"tester_\"+str(i))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************hyper-parameters****************\n",
      "epochs = 1000\n",
      "batch_size = 16\n",
      "soft_labels = False\n",
      "adv_weight = 0\n",
      "d_thresh = 0.9\n",
      "z_dim = 256\n",
      "z_dis = norm\n",
      "model_images_save_step = 5\n",
      "data = chair/\n",
      "device = cuda\n",
      "g_lr = 0.0025\n",
      "d_lr = 1e-05\n",
      "cube_len = 32\n",
      "leak_value = 0.2\n",
      "bias = False\n",
      "****************hyper-parameters****************\n",
      "Evaluation Mode...\n",
      "../outputs/dcgan/G.pth\n",
      "visualizing model\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "main.py\n",
    "\n",
    "Welcome, this is the entrance to 3dgan\n",
    "'''\n",
    "\n",
    "import argparse\n",
    "# from trainer import trainer\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# from tester import tester\n",
    "import params\n",
    "\n",
    "def str2bool(v):\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "def main():\n",
    "\n",
    "    # add arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # loggings parameters\n",
    "    parser.add_argument('--logs', type=str, default=None, help='logs by tensorboardX')\n",
    "    parser.add_argument('--local_test', type=str2bool, default=False, help='local test verbose')\n",
    "    parser.add_argument('--model_name', type=str, default=\"dcgan\", help='model name for saving')\n",
    "    \n",
    "    ## change to default=True for test in Jupyter\n",
    "    parser.add_argument('--test', type=str2bool, default=False, help='call tester.py')\n",
    "    parser.add_argument('--use_visdom', type=str2bool, default=False, help='visualization by visdom')\n",
    "    args = parser.parse_args(args=[])\n",
    "\n",
    "    # list params\n",
    "    params.print_params()\n",
    "\n",
    "    # run program\n",
    "    if args.test == False:\n",
    "        trainer(args)\n",
    "    else:\n",
    "        tester(args)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# voxels = getVoxelFromMat(temppath)\n",
    "# abc = voxels\n",
    "\n",
    "# #change positive / negative sign here to rotate model\n",
    "# X = abc[2]\n",
    "# Y = abc[0]\n",
    "# Z = abc[1]\n",
    "\n",
    "# fig = plt.figure(figsize=(10,10))\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# ax.scatter(X,Y,Z)\n",
    "\n",
    "# max_range = np.array([X.max()-X.min(), Y.max()-Y.min(), Z.max()-Z.min()]).max()\n",
    "\n",
    "# Xb = (0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][0].flatten() + 0.5*(X.max()+X.min()))\n",
    "# Yb = (0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][1].flatten() + 0.5*(Y.max()+Y.min()))\n",
    "# Zb = (0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][2].flatten() + 0.5*(Z.max()+Z.min()))\n",
    "\n",
    "# # Comment or uncomment following both lines to test the fake bounding box:\n",
    "# for xb, yb, zb in zip(Xb, Yb, Zb):\n",
    "#     ax.plot([xb], [yb], [zb], 'w')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
